/*
 * Copyright (c) 2024 EdgeImpulse Inc.
 *
 * Generated by Edge Impulse and licensed under the applicable Edge Impulse
 * Terms of Service. Community and Professional Terms of Service
 * (https://docs.edgeimpulse.com/page/terms-of-service) or Enterprise Terms of
 * Service (https://docs.edgeimpulse.com/page/enterprise-terms-of-service),
 * according to your product plan subscription (the “License”).
 *
 * This software, documentation and other associated files (collectively referred
 * to as the “Software”) is a single SDK variation generated by the Edge Impulse
 * platform and requires an active paid Edge Impulse subscription to use this
 * Software for any purpose.
 *
 * You may NOT use this Software unless you have an active Edge Impulse subscription
 * that meets the eligibility requirements for the applicable License, subject to
 * your full and continued compliance with the terms and conditions of the License,
 * including without limitation any usage restrictions under the applicable License.
 *
 * If you do not have an active Edge Impulse product plan subscription, or if use
 * of this Software exceeds the usage limitations of your Edge Impulse product plan
 * subscription, you are not permitted to use this Software and must immediately
 * delete and erase all copies of this Software within your control or possession.
 * Edge Impulse reserves all rights and remedies available to enforce its rights.
 *
 * Unless required by applicable law or agreed to in writing, the Software is
 * distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND,
 * either express or implied. See the License for the specific language governing
 * permissions, disclaimers and limitations under the License.
 */
// Generated on: 21.01.2025 09:28:25

#include <stdio.h>
#include <stdlib.h>
#include "edge-impulse-sdk/tensorflow/lite/c/builtin_op_data.h"
#include "edge-impulse-sdk/tensorflow/lite/c/common.h"
#include "edge-impulse-sdk/tensorflow/lite/micro/micro_mutable_op_resolver.h"
#include "edge-impulse-sdk/porting/ei_classifier_porting.h"

#if EI_CLASSIFIER_PRINT_STATE
#if defined(__cplusplus) && EI_C_LINKAGE == 1
extern "C" {
    extern void ei_printf(const char *format, ...);
}
#else
extern void ei_printf(const char *format, ...);
#endif
#endif

#define STRINGIZE(x) #x
#define STRINGIZE_VALUE_OF(x) STRINGIZE(x)

#if defined (__GNUC__)  /* GNU compiler */
#define ALIGN(X) __attribute__((aligned(X)))
#define DEFINE_SECTION(x) __attribute__((section(x)))
#elif defined (_MSC_VER)
#define ALIGN(X) __declspec(align(X))
#elif defined (__TASKING__) /* TASKING Compiler */
#define ALIGN(X) __align(X)
#define DEFINE_SECTION(x) __attribute__((section(x)))
#elif defined (__ARMCC_VERSION) /* Arm Compiler */
#define ALIGN(X) __ALIGNED(x)
#define DEFINE_SECTION(x) __attribute__((section(x)))
#elif defined (__ICCARM__) /* IAR Compiler */
#define ALIGN(x) __attribute__((aligned(x)))
#define DEFINE_SECTION(x) __attribute__((section(x)))
#elif defined (__clang__) /* LLVM/Clang Compiler */
#define ALIGN(X) __ALIGNED(x)
#define DEFINE_SECTION(x) __attribute__((section(x)))
#endif

#if defined(EI_MODEL_SECTION) && (defined(__GNUC__) || defined(__clang__))
#define MODEL_SECTION(X) __attribute__((section(STRINGIZE_VALUE_OF(X))))
#else
#define MODEL_SECTION(X)
#endif

#ifndef EI_MAX_SCRATCH_BUFFER_COUNT
#ifndef CONFIG_IDF_TARGET_ESP32S3
#define EI_MAX_SCRATCH_BUFFER_COUNT 4
#else
#define EI_MAX_SCRATCH_BUFFER_COUNT 4
#endif // CONFIG_IDF_TARGET_ESP32S3
#endif // EI_MAX_SCRATCH_BUFFER_COUNT

#ifndef EI_MAX_OVERFLOW_BUFFER_COUNT
#define EI_MAX_OVERFLOW_BUFFER_COUNT 10
#endif // EI_MAX_OVERFLOW_BUFFER_COUNT

using namespace tflite;
using namespace tflite::ops;
using namespace tflite::ops::micro;

namespace {

#if defined(EI_CLASSIFIER_ALLOCATION_STATIC_HIMAX) || defined(EI_CLASSIFIER_ALLOCATION_STATIC_HIMAX_GNU)
constexpr int kTensorArenaSize = 1376;
#else
constexpr int kTensorArenaSize = 352;
#endif

#if defined(EI_CLASSIFIER_ALLOCATION_STATIC)
#if defined (EI_TENSOR_ARENA_LOCATION)
uint8_t tensor_arena[kTensorArenaSize] ALIGN(16) DEFINE_SECTION(STRINGIZE_VALUE_OF(EI_TENSOR_ARENA_LOCATION));
#else
uint8_t tensor_arena[kTensorArenaSize] ALIGN(16);
#endif
#elif defined(EI_CLASSIFIER_ALLOCATION_STATIC_HIMAX)
#pragma Bss(".tensor_arena")
uint8_t tensor_arena[kTensorArenaSize] ALIGN(16);
#pragma Bss()
#elif defined(EI_CLASSIFIER_ALLOCATION_STATIC_HIMAX_GNU)
uint8_t tensor_arena[kTensorArenaSize] ALIGN(16) __attribute__((section(".tensor_arena")));
#else
#define EI_CLASSIFIER_ALLOCATION_HEAP 1
uint8_t* tensor_arena = NULL;
#endif

static uint8_t* tensor_boundary;
static uint8_t* current_location;

template <int SZ, class T> struct TfArray {
  int sz; T elem[SZ];
};

enum used_operators_e {
  OP_FULLY_CONNECTED,  OP_LAST
};

struct TensorInfo_t { // subset of TfLiteTensor used for initialization from constant memory
  TfLiteAllocationType allocation_type;
  void* data;
  TfLiteIntArray* dims;
  size_t bytes;
};

typedef struct {
  TfLiteTensor tensor;
  int16_t index;
} TfLiteTensorWithIndex;

typedef struct {
  TfLiteEvalTensor tensor;
  int16_t index;
} TfLiteEvalTensorWithIndex;

TfLiteContext ctx{};
static const int MAX_TFL_TENSOR_COUNT = 4;
static TfLiteTensorWithIndex tflTensors[MAX_TFL_TENSOR_COUNT];
static const int MAX_TFL_EVAL_COUNT = 4;
static TfLiteEvalTensorWithIndex tflEvalTensors[MAX_TFL_EVAL_COUNT];
TfLiteRegistration registrations[OP_LAST];

namespace g0 {
const TfArray<2, int> tensor_dimension0 = { 2, { 1,5 } };
const MODEL_SECTION(EI_MODEL_SECTION) ALIGN(16) float tensor_data1[10] = { 0.13315986096858978, -0.1507306843996048, 0, -0.23432490229606628, 1.8885252475738525, 1.3020706176757812, 1.8737889528274536, -1.3978703022003174, 1.8924473524093628, -1.6702777147293091, };
const TfArray<1, int> tensor_dimension1 = { 1, { 10 } };
const MODEL_SECTION(EI_MODEL_SECTION) ALIGN(16) float tensor_data2[20] = { 1.8658319711685181, 1.973921537399292, 0.42562100291252136, -0.36253282427787781, 0.46967965364456177, 0.40858408808708191, -0.14787013828754425, 1.6663496494293213, -0.85836964845657349, 0, 1.5988408327102661, -0.44704160094261169, -0.30563452839851379, -1.065935492515564, -0.25195056200027466, 0, -1.0650467872619629, 1.8714003562927246, 1.3910692930221558, -0.097455874085426331, };
const TfArray<1, int> tensor_dimension2 = { 1, { 20 } };
const MODEL_SECTION(EI_MODEL_SECTION) ALIGN(4) float tensor_data3[1] = { 1.9005898237228394, };
const TfArray<1, int> tensor_dimension3 = { 1, { 1 } };
const MODEL_SECTION(EI_MODEL_SECTION) ALIGN(16) float tensor_data4[20*5] = { 
  0.038737960159778595, -0.042592588812112808, -0.20824332535266876, 0.59765273332595825, 0.41201579570770264, 
  -0.47154128551483154, -0.17424063384532928, 0.43379473686218262, 0.61038142442703247, 0.082915730774402618, 
  0.31416389346122742, -0.074110083281993866, -0.62847322225570679, -0.96373969316482544, 0.46804210543632507, 
  -0.30098190903663635, 0.30281305313110352, -0.86267626285552979, 0.4048924446105957, 0.40106686949729919, 
  0.29707342386245728, 0.16446247696876526, -0.086635783314704895, -0.3075195848941803, -0.40430855751037598, 
  -0.27869147062301636, 0.22658033668994904, 0.1931467205286026, 0.053485680371522903, -0.02460743673145771, 
  -0.031991429626941681, -0.13426484167575836, -0.018549203872680664, 0.5049368143081665, -2.1426773071289062, 
  0.11316163092851639, -0.75841915607452393, -0.062137946486473083, 0.50723707675933838, 0.21265865862369537, 
  0.017763921990990639, 0.33303350210189819, 0.33294105529785156, -0.13280729949474335, -0.87444740533828735, 
  -0.40604421496391296, 0.21802499890327454, -0.41265898942947388, -0.031551629304885864, -0.28229483962059021, 
  0.4695320725440979, 0.1603606641292572, 0.13150754570960999, -0.3275875449180603, -0.16887898743152618, 
  -0.16113559901714325, -0.078875243663787842, 0.48999375104904175, -0.040638342499732971, -0.19148316979408264, 
  -1.0671398639678955, -1.4931902885437012, 0.2670854926109314, 0.28465387225151062, 0.14916837215423584, 
  0.0012699470389634371, -0.86294728517532349, -0.32985672354698181, -0.5277327299118042, 0.84610384702682495, 
  0.31787803769111633, -1.5287532806396484, -0.38287022709846497, 0.31615301966667175, -0.36123842000961304, 
  -0.00043928623199462891, 0.41017267107963562, -0.3616490364074707, -0.45726239681243896, -0.45477256178855896, 
  -0.052145399153232574, -0.86386895179748535, -0.20362848043441772, -0.61232477426528931, 0.73124271631240845, 
  -0.1157633364200592, 0.1435711681842804, 0.30705553293228149, 0.49280458688735962, 0.62825381755828857, 
  -0.95066291093826294, -0.49627989530563354, 0.43930143117904663, -0.18771800398826599, 0.22964701056480408, 
  -0.070870012044906616, 0.2607899010181427, -0.056821897625923157, -0.3301442563533783, -0.18612627685070038, 
};
const TfArray<2, int> tensor_dimension4 = { 2, { 20,5 } };
const MODEL_SECTION(EI_MODEL_SECTION) ALIGN(16) float tensor_data5[10*20] = { 
  0.23556002974510193, -0.17734234035015106, -0.19334186613559723, 0.008828471414744854, 0.22980308532714844, 0.12283696234226227, -0.081952236592769623, -0.58113408088684082, 0.037731926888227463, -0.19483354687690735, -0.098183430731296539, -0.14908614754676819, 0.24257105588912964, 0.4677349328994751, 0.33980730175971985, -0.31586644053459167, -0.024184975773096085, -0.21106706559658051, -0.26989120244979858, 0.12952609360218048, 
  -0.36586916446685791, -0.58725947141647339, 0.25989925861358643, 0.10596992075443268, 0.20556908845901489, -0.30720150470733643, -0.19914223253726959, -0.36983609199523926, -0.35554879903793335, 0.069873809814453125, -0.35146576166152954, -0.2023371160030365, 0.2409820556640625, 0.084498703479766846, 0.26755255460739136, 0.3430597186088562, -0.19190970063209534, -0.019370967522263527, -0.1693665087223053, -0.11774033308029175, 
  -0.086540102958679199, -0.36983108520507812, -0.011426568031311035, 0.40303337574005127, -0.18503651022911072, -0.22609998285770416, -0.13627669215202332, 0.078819572925567627, -0.15676471590995789, -0.043710947036743164, 0.12338340282440186, 0.19389015436172485, -0.081969767808914185, -0.33017858862876892, -0.050489902496337891, -0.26666605472564697, 0.32243669033050537, -0.3727266788482666, -0.38322222232818604, -0.30915829539299011, 
  -0.062498640269041061, 0.055257204920053482, 0.28128871321678162, 0.017987495288252831, -0.35117363929748535, 0.21316654980182648, -0.87261247634887695, -0.51895338296890259, -0.94344919919967651, 0.28100210428237915, 0.093656234443187714, 0.12062422186136246, 0.071762748062610626, -0.1361117959022522, -0.082239292562007904, -0.17162406444549561, -0.054594948887825012, -0.31120774149894714, 1.054058313369751, 0.38262566924095154, 
  0.044724803417921066, 0.38734164834022522, 0.39420685172080994, -1.283078670501709, -0.35221520066261292, 0.21632824838161469, -1.0814691781997681, 0.25550577044487, -0.2837863564491272, 0.23458927869796753, 0.23997245728969574, 0.16187091171741486, -0.98034411668777466, -0.53187745809555054, -0.15630733966827393, -0.36372420191764832, -0.94814646244049072, 0.47717344760894775, 0.71852517127990723, 0.30455353856086731, 
  -0.33281180262565613, 0.36137920618057251, -0.51905488967895508, 0.15373280644416809, -0.72898685932159424, -1.2793581485748291, -0.67590540647506714, 0.62677478790283203, -1.0771456956863403, -0.17979496717453003, -0.088211975991725922, 0.024366868659853935, -1.926336407661438, -0.33543163537979126, -0.84850907325744629, -0.25903475284576416, -1.141329288482666, 0.098743580281734467, 0.40949109196662903, -0.035801656544208527, 
  0.58082616329193115, 0.35233089327812195, 0.52692002058029175, -1.3952203989028931, 0.28507208824157715, 0.2617151141166687, -0.88999873399734497, 0.035570193082094193, -0.026130909100174904, 0.0096309185028076172, 0.14739914238452911, 0.11196001619100571, -1.1576389074325562, -0.84772169589996338, -0.18920004367828369, -0.06756243109703064, -0.50852376222610474, 0.03586861863732338, 0.38666644692420959, -0.052729170769453049, 
  -0.27776822447776794, 0.78597933053970337, -0.21777191758155823, 1.2728805541992188, 0.10659052431583405, 0.30613130331039429, 0.83007925748825073, -0.46802908182144165, 0.33812776207923889, -0.11473512649536133, -0.15005338191986084, 0.68395668268203735, 1.1874963045120239, 1.4350215196609497, 0.072177894413471222, 0.19092845916748047, 1.5867507457733154, 0.017158316448330879, -0.45833218097686768, 0.21883031725883484, 
  0.48031312227249146, 0.33549728989601135, 0.97051608562469482, -0.9411461353302002, 0.31488019227981567, 0.09420342743396759, -1.3426972627639771, 0.071971915662288666, -0.036132819950580597, 0.047066181898117065, 0.27747067809104919, 0.042173612862825394, -0.89946985244750977, -1.0988190174102783, -0.35875222086906433, 0.36558049917221069, -1.0779986381530762, 0.38482457399368286, 0.27412483096122742, -0.043787870556116104, 
  0.020271647721529007, -0.34794119000434875, -0.46127557754516602, 1.0517222881317139, 0.26384052634239197, 0.41133004426956177, 0.84853583574295044, -0.079535506665706635, 0.23877823352813721, -0.35648933053016663, -0.16204887628555298, 0.23926600813865662, -0.50958216190338135, 0.065142132341861725, 0.28021833300590515, -0.071695268154144287, 0.33569744229316711, 0.30146154761314392, -0.80599319934844971, 0.21714077889919281, 
};
const TfArray<2, int> tensor_dimension5 = { 2, { 10,20 } };
const MODEL_SECTION(EI_MODEL_SECTION) ALIGN(16) float tensor_data6[1*10] = { 
  0.32669097185134888, 0.25262084603309631, -0.59334319829940796, -0.45121359825134277, 0.54714971780776978, 0.59828871488571167, 0.67551666498184204, -0.4551200270652771, 0.82901382446289062, -0.55685365200042725, 
};
const TfArray<2, int> tensor_dimension6 = { 2, { 1,10 } };
const TfArray<2, int> tensor_dimension7 = { 2, { 1,20 } };
const TfArray<2, int> tensor_dimension8 = { 2, { 1,10 } };
const TfArray<2, int> tensor_dimension9 = { 2, { 1,1 } };
const TfLiteFullyConnectedParams opdata0 = { kTfLiteActRelu, kTfLiteFullyConnectedWeightsFormatDefault, false, false };
const TfArray<3, int> inputs0 = { 3, { 0,4,2 } };
const TfArray<1, int> outputs0 = { 1, { 7 } };
const TfLiteFullyConnectedParams opdata1 = { kTfLiteActRelu, kTfLiteFullyConnectedWeightsFormatDefault, false, false };
const TfArray<3, int> inputs1 = { 3, { 7,5,1 } };
const TfArray<1, int> outputs1 = { 1, { 8 } };
const TfLiteFullyConnectedParams opdata2 = { kTfLiteActNone, kTfLiteFullyConnectedWeightsFormatDefault, false, false };
const TfArray<3, int> inputs2 = { 3, { 8,6,3 } };
const TfArray<1, int> outputs2 = { 1, { 9 } };
};

TensorInfo_t tensorData[] = {
{ kTfLiteArenaRw, (int32_t*)(tensor_arena + 80), (TfLiteIntArray*)&g0::tensor_dimension0, 20, },
{ kTfLiteMmapRo, (int32_t*)g0::tensor_data1, (TfLiteIntArray*)&g0::tensor_dimension1, 40, },
{ kTfLiteMmapRo, (int32_t*)g0::tensor_data2, (TfLiteIntArray*)&g0::tensor_dimension2, 80, },
{ kTfLiteMmapRo, (int32_t*)g0::tensor_data3, (TfLiteIntArray*)&g0::tensor_dimension3, 4, },
{ kTfLiteMmapRo, (int32_t*)g0::tensor_data4, (TfLiteIntArray*)&g0::tensor_dimension4, 400, },
{ kTfLiteMmapRo, (int32_t*)g0::tensor_data5, (TfLiteIntArray*)&g0::tensor_dimension5, 800, },
{ kTfLiteMmapRo, (int32_t*)g0::tensor_data6, (TfLiteIntArray*)&g0::tensor_dimension6, 40, },
{ kTfLiteArenaRw, (int32_t*)(tensor_arena + 0), (TfLiteIntArray*)&g0::tensor_dimension7, 80, },
{ kTfLiteArenaRw, (int32_t*)(tensor_arena + 80), (TfLiteIntArray*)&g0::tensor_dimension8, 40, },
{ kTfLiteArenaRw, (int32_t*)(tensor_arena + 0), (TfLiteIntArray*)&g0::tensor_dimension9, 4, },
};

#ifndef TF_LITE_STATIC_MEMORY
TfLiteNode tflNodes[3] = {
{ (TfLiteIntArray*)&g0::inputs0, (TfLiteIntArray*)&g0::outputs0, (TfLiteIntArray*)&g0::inputs0, nullptr, nullptr, const_cast<void*>(static_cast<const void*>(&g0::opdata0)), nullptr, 0, },
{ (TfLiteIntArray*)&g0::inputs1, (TfLiteIntArray*)&g0::outputs1, (TfLiteIntArray*)&g0::inputs1, nullptr, nullptr, const_cast<void*>(static_cast<const void*>(&g0::opdata1)), nullptr, 0, },
{ (TfLiteIntArray*)&g0::inputs2, (TfLiteIntArray*)&g0::outputs2, (TfLiteIntArray*)&g0::inputs2, nullptr, nullptr, const_cast<void*>(static_cast<const void*>(&g0::opdata2)), nullptr, 0, },
};
#else
TfLiteNode tflNodes[3] = {
{ (TfLiteIntArray*)&g0::inputs0, (TfLiteIntArray*)&g0::outputs0, (TfLiteIntArray*)&g0::inputs0, nullptr, const_cast<void*>(static_cast<const void*>(&g0::opdata0)), nullptr, 0, },
{ (TfLiteIntArray*)&g0::inputs1, (TfLiteIntArray*)&g0::outputs1, (TfLiteIntArray*)&g0::inputs1, nullptr, const_cast<void*>(static_cast<const void*>(&g0::opdata1)), nullptr, 0, },
{ (TfLiteIntArray*)&g0::inputs2, (TfLiteIntArray*)&g0::outputs2, (TfLiteIntArray*)&g0::inputs2, nullptr, const_cast<void*>(static_cast<const void*>(&g0::opdata2)), nullptr, 0, },
};
#endif

used_operators_e used_ops[] =
{OP_FULLY_CONNECTED, OP_FULLY_CONNECTED, OP_FULLY_CONNECTED, };


// Indices into tflTensors and tflNodes for subgraphs
const size_t tflTensors_subgraph_index[] = {0, 10, };
const size_t tflNodes_subgraph_index[] = {0, 3, };

// Input/output tensors
static const int in_tensor_indices[] = {
  0, 
};

static const int out_tensor_indices[] = {
  9, 
};


size_t current_subgraph_index = 0;

static void init_tflite_tensor(size_t i, TfLiteTensor *tensor) {
  tensor->type = kTfLiteFloat32;
  tensor->is_variable = false;

#if defined(EI_CLASSIFIER_ALLOCATION_HEAP)
  tensor->allocation_type = tensorData[i].allocation_type;
#else
  tensor->allocation_type = (tensor_arena <= tensorData[i].data && tensorData[i].data < tensor_arena + kTensorArenaSize) ? kTfLiteArenaRw : kTfLiteMmapRo;
#endif
  tensor->bytes = tensorData[i].bytes;
  tensor->dims = tensorData[i].dims;

#if defined(EI_CLASSIFIER_ALLOCATION_HEAP)
  if(tensor->allocation_type == kTfLiteArenaRw){
    uint8_t* start = (uint8_t*) ((uintptr_t)tensorData[i].data + (uintptr_t) tensor_arena);

    tensor->data.data =  start;
  }
  else {
      tensor->data.data = tensorData[i].data;
  }
#else
  tensor->data.data = tensorData[i].data;
#endif // EI_CLASSIFIER_ALLOCATION_HEAP
  tensor->quantization.type = kTfLiteNoQuantization;

}

static void init_tflite_eval_tensor(int i, TfLiteEvalTensor *tensor) {

  tensor->type = kTfLiteFloat32;

  tensor->dims = tensorData[i].dims;

#if defined(EI_CLASSIFIER_ALLOCATION_HEAP)
  auto allocation_type = tensorData[i].allocation_type;
  if(allocation_type == kTfLiteArenaRw) {
    uint8_t* start = (uint8_t*) ((uintptr_t)tensorData[i].data + (uintptr_t) tensor_arena);

    tensor->data.data =  start;
  }
  else {
    tensor->data.data = tensorData[i].data;
  }
#else
  tensor->data.data = tensorData[i].data;
#endif // EI_CLASSIFIER_ALLOCATION_HEAP
}

static void* overflow_buffers[EI_MAX_OVERFLOW_BUFFER_COUNT];
static size_t overflow_buffers_ix = 0;
static void * AllocatePersistentBufferImpl(struct TfLiteContext* ctx,
                                       size_t bytes) {
  void *ptr;
  uint32_t align_bytes = (bytes % 16) ? 16 - (bytes % 16) : 0;

  if (current_location - (bytes + align_bytes) < tensor_boundary) {
    if (overflow_buffers_ix > EI_MAX_OVERFLOW_BUFFER_COUNT - 1) {
      ei_printf("ERR: Failed to allocate persistent buffer of size %d, does not fit in tensor arena and reached EI_MAX_OVERFLOW_BUFFER_COUNT\n",
        (int)bytes);
      return NULL;
    }

    // OK, this will look super weird, but.... we have CMSIS-NN buffers which
    // we cannot calculate beforehand easily.
    ptr = ei_calloc(bytes, 1);
    if (ptr == NULL) {
      ei_printf("ERR: Failed to allocate persistent buffer of size %d\n", (int)bytes);
      return NULL;
    }
    overflow_buffers[overflow_buffers_ix++] = ptr;
    return ptr;
  }

  current_location -= bytes;

  // align to the left aligned boundary of 16 bytes
  current_location -= 15; // for alignment
  current_location += 16 - ((uintptr_t)(current_location) & 15);

  ptr = current_location;
  memset(ptr, 0, bytes);

  return ptr;
}

typedef struct {
  size_t bytes;
  void *ptr;
} scratch_buffer_t;

static scratch_buffer_t scratch_buffers[EI_MAX_SCRATCH_BUFFER_COUNT];
static size_t scratch_buffers_ix = 0;

static TfLiteStatus RequestScratchBufferInArenaImpl(struct TfLiteContext* ctx, size_t bytes,
                                                int* buffer_idx) {
  if (scratch_buffers_ix > EI_MAX_SCRATCH_BUFFER_COUNT - 1) {
    ei_printf("ERR: Failed to allocate scratch buffer of size %d, reached EI_MAX_SCRATCH_BUFFER_COUNT\n",
      (int)bytes);
    return kTfLiteError;
  }

  scratch_buffer_t b;
  b.bytes = bytes;

  b.ptr = AllocatePersistentBufferImpl(ctx, b.bytes);
  if (!b.ptr) {
    ei_printf("ERR: Failed to allocate scratch buffer of size %d\n",
      (int)bytes);
    return kTfLiteError;
  }

  scratch_buffers[scratch_buffers_ix] = b;
  *buffer_idx = scratch_buffers_ix;

  scratch_buffers_ix++;

  return kTfLiteOk;
}

static void* GetScratchBufferImpl(struct TfLiteContext* ctx, int buffer_idx) {
  if (buffer_idx > (int)scratch_buffers_ix) {
    return NULL;
  }
  return scratch_buffers[buffer_idx].ptr;
}

static const uint16_t TENSOR_IX_UNUSED = 0x7FFF;

static void ResetTensors() {
  for (size_t ix = 0; ix < MAX_TFL_TENSOR_COUNT; ix++) {
    tflTensors[ix].index = TENSOR_IX_UNUSED;
  }
  for (size_t ix = 0; ix < MAX_TFL_EVAL_COUNT; ix++) {
    tflEvalTensors[ix].index = TENSOR_IX_UNUSED;
  }
}

static TfLiteTensor* GetTensorImpl(const struct TfLiteContext* context,
                               int tensor_idx) {

  tensor_idx = tflTensors_subgraph_index[current_subgraph_index] + tensor_idx;

  for (size_t ix = 0; ix < MAX_TFL_TENSOR_COUNT; ix++) {
    // already used? OK!
    if (tflTensors[ix].index == tensor_idx) {
      return &tflTensors[ix].tensor;
    }
    // passed all the ones we've used, so end of the list?
    if (tflTensors[ix].index == TENSOR_IX_UNUSED) {
      // init the tensor
      init_tflite_tensor(tensor_idx, &tflTensors[ix].tensor);
      tflTensors[ix].index = tensor_idx;
      return &tflTensors[ix].tensor;
    }
  }

  ei_printf("ERR: GetTensor called beyond MAX_TFL_TENSOR_COUNT (%d)\n", MAX_TFL_TENSOR_COUNT);
  return nullptr;
}

static TfLiteEvalTensor* GetEvalTensorImpl(const struct TfLiteContext* context,
                                       int tensor_idx) {

  tensor_idx = tflTensors_subgraph_index[current_subgraph_index] + tensor_idx;

  for (size_t ix = 0; ix < MAX_TFL_EVAL_COUNT; ix++) {
    // already used? OK!
    if (tflEvalTensors[ix].index == tensor_idx) {
      return &tflEvalTensors[ix].tensor;
    }
    // passed all the ones we've used, so end of the list?
    if (tflEvalTensors[ix].index == TENSOR_IX_UNUSED) {
      // init the tensor
      init_tflite_eval_tensor(tensor_idx, &tflEvalTensors[ix].tensor);
      tflEvalTensors[ix].index = tensor_idx;
      return &tflEvalTensors[ix].tensor;
    }
  }

  ei_printf("ERR: GetTensor called beyond MAX_TFL_EVAL_COUNT (%d)\n", (int)MAX_TFL_EVAL_COUNT);
  return nullptr;
}

class EonMicroContext : public MicroContext {
 public:
 
  EonMicroContext(): MicroContext(nullptr, nullptr, nullptr) { }

  void* AllocatePersistentBuffer(size_t bytes) {
    return AllocatePersistentBufferImpl(nullptr, bytes);
  }

  TfLiteStatus RequestScratchBufferInArena(size_t bytes,
                                           int* buffer_index) {
  return RequestScratchBufferInArenaImpl(nullptr, bytes, buffer_index);
  }

  void* GetScratchBuffer(int buffer_index) {
    return GetScratchBufferImpl(nullptr, buffer_index);
  }
 
  TfLiteTensor* AllocateTempTfLiteTensor(int tensor_index) {
    return GetTensorImpl(nullptr, tensor_index);
  }

  void DeallocateTempTfLiteTensor(TfLiteTensor* tensor) {
    return;
  }

  bool IsAllTempTfLiteTensorDeallocated() {
    return true;
  }

  TfLiteEvalTensor* GetEvalTensor(int tensor_index) {
    return GetEvalTensorImpl(nullptr, tensor_index);
  }

};


} // namespace

TfLiteStatus tflite_learn_10_init( void*(*alloc_fnc)(size_t,size_t) ) {
#ifdef EI_CLASSIFIER_ALLOCATION_HEAP
  tensor_arena = (uint8_t*) alloc_fnc(16, kTensorArenaSize);
  if (!tensor_arena) {
    ei_printf("ERR: failed to allocate tensor arena\n");
    return kTfLiteError;
  }
#else
  memset(tensor_arena, 0, kTensorArenaSize);
#endif
  tensor_boundary = tensor_arena;
  current_location = tensor_arena + kTensorArenaSize;

  EonMicroContext micro_context_;
  
  // Set microcontext as the context ptr
  ctx.impl_ = static_cast<void*>(&micro_context_);
  // Setup tflitecontext functions
  ctx.AllocatePersistentBuffer = &AllocatePersistentBufferImpl;
  ctx.RequestScratchBufferInArena = &RequestScratchBufferInArenaImpl;
  ctx.GetScratchBuffer = &GetScratchBufferImpl;
  ctx.GetTensor = &GetTensorImpl;
  ctx.GetEvalTensor = &GetEvalTensorImpl;
  ctx.ReportError = &MicroContextReportOpError;

  ctx.tensors_size = 10;
  for (size_t i = 0; i < 10; ++i) {
    TfLiteTensor tensor;
    init_tflite_tensor(i, &tensor);
    if (tensor.allocation_type == kTfLiteArenaRw) {
      auto data_end_ptr = (uint8_t*)tensor.data.data + tensorData[i].bytes;
      if (data_end_ptr > tensor_boundary) {
        tensor_boundary = data_end_ptr;
      }
    }
  }

  if (tensor_boundary > current_location /* end of arena size */) {
    ei_printf("ERR: tensor arena is too small, does not fit model - even without scratch buffers\n");
    return kTfLiteError;
  }

  registrations[OP_FULLY_CONNECTED] = Register_FULLY_CONNECTED();

  for (size_t g = 0; g < 1; ++g) {
    current_subgraph_index = g;
    for(size_t i = tflNodes_subgraph_index[g]; i < tflNodes_subgraph_index[g+1]; ++i) {
      if (registrations[used_ops[i]].init) {
        tflNodes[i].user_data = registrations[used_ops[i]].init(&ctx, (const char*)tflNodes[i].builtin_data, 0);
      }
    }
  }
  current_subgraph_index = 0;

  for(size_t g = 0; g < 1; ++g) {
    current_subgraph_index = g;
    for(size_t i = tflNodes_subgraph_index[g]; i < tflNodes_subgraph_index[g+1]; ++i) {
      if (registrations[used_ops[i]].prepare) {
        ResetTensors();
        TfLiteStatus status = registrations[used_ops[i]].prepare(&ctx, &tflNodes[i]);
        if (status != kTfLiteOk) {
          return status;
        }
      }
    }
  }
  current_subgraph_index = 0;

  return kTfLiteOk;
}

TfLiteStatus tflite_learn_10_input(int index, TfLiteTensor *tensor) {
  init_tflite_tensor(in_tensor_indices[index], tensor);
  return kTfLiteOk;
}

TfLiteStatus tflite_learn_10_output(int index, TfLiteTensor *tensor) {
  init_tflite_tensor(out_tensor_indices[index], tensor);
  return kTfLiteOk;
}

TfLiteStatus tflite_learn_10_invoke() {
  for (size_t i = 0; i < 3; ++i) {
    ResetTensors();

    TfLiteStatus status = registrations[used_ops[i]].invoke(&ctx, &tflNodes[i]);

#if EI_CLASSIFIER_PRINT_STATE
    ei_printf("layer %lu\n", i);
    ei_printf("    inputs:\n");
    for (size_t ix = 0; ix < tflNodes[i].inputs->size; ix++) {
      auto d = tensorData[tflNodes[i].inputs->data[ix]];

      size_t data_ptr = (size_t)d.data;

      if (d.allocation_type == kTfLiteArenaRw) {
        data_ptr = (size_t)tensor_arena + data_ptr;
      }

      if (d.type == TfLiteType::kTfLiteInt8) {
        int8_t* data = (int8_t*)data_ptr;
        ei_printf("        %lu (%zu bytes, ptr=%p, alloc_type=%d, type=%d): ", ix, d.bytes, data, (int)d.allocation_type, (int)d.type);
        for (size_t jx = 0; jx < d.bytes; jx++) {
          ei_printf("%d ", data[jx]);
        }
      }
      else {
        float* data = (float*)data_ptr;
        ei_printf("        %lu (%zu bytes, ptr=%p, alloc_type=%d, type=%d): ", ix, d.bytes, data, (int)d.allocation_type, (int)d.type);
        for (size_t jx = 0; jx < d.bytes / 4; jx++) {
          ei_printf("%f ", data[jx]);
        }
      }
      ei_printf("\n");
    }
    ei_printf("\n");

    ei_printf("    outputs:\n");
    for (size_t ix = 0; ix < tflNodes[i].outputs->size; ix++) {
      auto d = tensorData[tflNodes[i].outputs->data[ix]];

      size_t data_ptr = (size_t)d.data;

      if (d.allocation_type == kTfLiteArenaRw) {
        data_ptr = (size_t)tensor_arena + data_ptr;
      }

      if (d.type == TfLiteType::kTfLiteInt8) {
        int8_t* data = (int8_t*)data_ptr;
        ei_printf("        %lu (%zu bytes, ptr=%p, alloc_type=%d, type=%d): ", ix, d.bytes, data, (int)d.allocation_type, (int)d.type);
        for (size_t jx = 0; jx < d.bytes; jx++) {
          ei_printf("%d ", data[jx]);
        }
      }
      else {
        float* data = (float*)data_ptr;
        ei_printf("        %lu (%zu bytes, ptr=%p, alloc_type=%d, type=%d): ", ix, d.bytes, data, (int)d.allocation_type, (int)d.type);
        for (size_t jx = 0; jx < d.bytes / 4; jx++) {
          ei_printf("%f ", data[jx]);
        }
      }
      ei_printf("\n");
    }
    ei_printf("\n");
#endif // EI_CLASSIFIER_PRINT_STATE

    if (status != kTfLiteOk) {
      return status;
    }
  }
  return kTfLiteOk;
}

TfLiteStatus tflite_learn_10_reset( void (*free_fnc)(void* ptr) ) {
#ifdef EI_CLASSIFIER_ALLOCATION_HEAP
  free_fnc(tensor_arena);
#endif

  // scratch buffers are allocated within the arena, so just reset the counter so memory can be reused
  scratch_buffers_ix = 0;

  // overflow buffers are on the heap, so free them first
  for (size_t ix = 0; ix < overflow_buffers_ix; ix++) {
    ei_free(overflow_buffers[ix]);
  }
  overflow_buffers_ix = 0;
  return kTfLiteOk;
}
